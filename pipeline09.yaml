name: $(Date:yyyyMMdd)$(Rev:.r)

trigger: none # Manual trigger only

parameters:
- name: sqlScriptName
  displayName: 'SQL Script Name'
  type: string
  default: 'script.sql'
- name: dryRun
  displayName: 'Dry Run (Validation Only)'
  type: boolean
  default: false
- name: enableBackup
  displayName: 'Enable Backup Before Execution'
  type: boolean
  default: true
- name: agentPool
  displayName: 'Agent Pool'
  type: string
  default: 'self1'

variables:
  sqlScriptPath: '$(Pipeline.Workspace)/sql/${{ parameters.sqlScriptName }}'
  backupPath: '$(Pipeline.Workspace)/backup'
  logsPath: '$(Pipeline.Workspace)/logs'
  storageAccountName: 'sqlautostacc'
  containerName: 'rawsql'
  backupContainerName: 'backups'
  keyVaultName: 'sql-validator-kv'
  secretName: 'sql-conn-string'

stages:

# ============================================================
# Download and Validate Stage
# ============================================================
- stage: Download_And_Validate
  displayName: 'Download and Validate SQL Script'
  jobs:
  - job: DownloadScript
    displayName: 'Download SQL Script from Blob Storage'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 10
    steps:
    - checkout: none

    - task: PowerShell@2
      displayName: 'Verify Agent Prerequisites'
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "Checking agent prerequisites."

          # Check PowerShell version
          $psVersion = $PSVersionTable.PSVersion
          Write-Host "PowerShell Version: $psVersion"
          if ($psVersion.Major -lt 5) {
              Write-Error "PowerShell 5.0 or higher required"
              exit 1
          }

          # Check Python
          try {
              $pythonVersion = python --version 2>&1
              Write-Host "Python: $pythonVersion"
              
              # Check if sqlparse is installed
              $sqlparseCheck = python -c "import sqlparse; print('sqlparse is available')" 2>&1
              if ($LASTEXITCODE -ne 0) {
                  Write-Host "Installing sqlparse module."
                  python -m pip install sqlparse==0.4.4
              } else {
                  Write-Host "✓ sqlparse module is already installed"
              }
          } catch {
              Write-Error "Python not found or not working properly. Please ensure Python 3.x is installed and in PATH"
              Get-Command python* -CommandType Application | Format-Table Name, Path
              exit 1
          }

          # Check Az PowerShell module
          $azRequired = @('Az.Accounts','Az.KeyVault','Az.Storage')
          foreach ($m in $azRequired) {
              if (-not (Get-Module -ListAvailable -Name $m)) {
                  Write-Host "Installing $m"
                  Install-Module -Name $m -Force -AllowClobber -Scope CurrentUser
              } else {
                  Write-Host "✓ $m present"
              }
          }

          # Check SqlServer module
          if (-not (Get-Module -ListAvailable -Name SqlServer)) {
              Write-Host "Installing SqlServer PowerShell module."
              Install-Module -Name SqlServer -Force -Scope CurrentUser
          } else {
              Write-Host "✓ SqlServer module present"
          }

    - task: AzurePowerShell@5
      displayName: 'Download SQL Script from Blob'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          try {
              Write-Host "Preparing download path..."
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/sql" | Out-Null

              Write-Host "Finding storage account $(storageAccountName)"
              $storageAccount = Get-AzStorageAccount | Where-Object { $_.StorageAccountName -eq "$(storageAccountName)" }
              if (-not $storageAccount) {
                  throw "Storage account '$(storageAccountName)' not found"
              }
              $ctx = $storageAccount.Context

              Write-Host "Downloading script: ${{ parameters.sqlScriptName }}"
              Get-AzStorageBlobContent `
                -Container "$(containerName)" `
                -Blob "${{ parameters.sqlScriptName }}" `
                -Destination "$(sqlScriptPath)" `
                -Context $ctx `
                -Force

              if (-not (Test-Path "$(sqlScriptPath)")) {
                  throw "Failed to download SQL script to $(sqlScriptPath)"
              }

              $fileSize = (Get-Item "$(sqlScriptPath)").Length
              Write-Host "✓ Script downloaded successfully ($fileSize bytes)"
              Get-Content "$(sqlScriptPath)" -TotalCount 8 | ForEach-Object { Write-Host "  $_" }
          } catch {
              Write-Error "Download failed: $($_.Exception.Message)"
              exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish SQL Script'
      inputs:
        targetPath: '$(Pipeline.Workspace)/sql'
        artifact: 'SQLScript'
        publishLocation: 'pipeline'

  - job: ValidateScript
    displayName: 'Syntax and Security Validation'
    dependsOn: DownloadScript
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 15
    steps:
    - checkout: none

    - task: DownloadPipelineArtifact@2
      displayName: 'Download SQL Script Artifact'
      inputs:
        artifact: 'SQLScript'
        path: '$(Pipeline.Workspace)/sql'

    - task: PythonScript@0
      name: SQLValidation
      displayName: 'SQL Syntax and Security Validation'
      inputs:
        scriptSource: 'inline'
        script: |
          import sqlparse
          import sys
          import os
          import re
          import json

          # Debug info
          print("=== DEBUG INFORMATION ===")
          print("PIPELINE_WORKSPACE:", os.environ.get('PIPELINE_WORKSPACE'))
          print("SQL_SCRIPT_PATH:", os.environ.get('SQL_SCRIPT_PATH'))

          pipeline_workspace = os.environ.get('PIPELINE_WORKSPACE') or os.environ.get('SYSTEM_DEFAULTWORKINGDIRECTORY') or os.getcwd()
          script_path = os.environ.get('SQL_SCRIPT_PATH')
          if not script_path:
              script_path = os.path.join(pipeline_workspace, 'sql', os.environ.get('SQL_SCRIPT_NAME_PARAM', 'script.sql'))

          print("Using script path:", script_path)
          if not os.path.exists(script_path):
              print("##vso[task.logissue type=error]SQL script not found at " + script_path)
              sys.exit(1)

          def validate_sql_syntax(file_path):
              with open(file_path, 'r', encoding='utf-8') as f:
                  sql_content = f.read()
              if not sql_content.strip():
                  print("##vso[task.logissue type=error]SQL file is empty")
                  return False
              parsed = sqlparse.parse(sql_content)
              if not parsed:
                  print("##vso[task.logissue type=error]Failed to parse SQL content")
                  return False
              print("Basic SQL syntax parse OK - statements found:", len(parsed))
              return True

          def extract_affected_objects(file_path):
              with open(file_path, 'r', encoding='utf-8') as f:
                  sql_content = f.read()

              # Remove comments
              sql_no_comments = re.sub(r'--.*$', '', sql_content, flags=re.MULTILINE)
              sql_no_comments = re.sub(r'/\*.*?\*/', '', sql_no_comments, flags=re.DOTALL)

              procedures = re.findall(r'\b(?:ALTER|DROP)\s+PROCEDURE\s+([^\s;]+)', sql_no_comments, flags=re.IGNORECASE)
              functions = re.findall(r'\b(?:ALTER|DROP)\s+FUNCTION\s+([^\s;]+)', sql_no_comments, flags=re.IGNORECASE)
              views = re.findall(r'\b(?:ALTER|DROP)\s+VIEW\s+([^\s;]+)', sql_no_comments, flags=re.IGNORECASE)
              tables = re.findall(r'\b(?:ALTER|DROP)\s+TABLE\s+([^\s;]+)', sql_no_comments, flags=re.IGNORECASE)

              data = {
                  "procedures": procedures,
                  "functions": functions,
                  "views": views,
                  "tables": tables
              }
              return data

          def check_security_policies(file_path):
              with open(file_path, 'r', encoding='utf-8') as f:
                  sql_content = f.read()
              issues = []
              warnings = []

              statements = sqlparse.parse(sql_content)
              for i, stmt in enumerate(statements):
                  s = str(stmt).upper()
                  # Basic dangerous checks simplified
                  if 'DELETE' in s and 'WHERE' not in s:
                      issues.append(f"Statement {i+1}: DELETE without WHERE")
                  if 'TRUNCATE TABLE' in s:
                      issues.append(f"Statement {i+1}: TRUNCATE TABLE")
                  if re.search(r'\bDROP\s+TABLE\b', s):
                      issues.append(f"Statement {i+1}: DROP TABLE detected")
                  if 'EXEC(' in s or 'SP_EXECUTESQL' in s:
                      warnings.append(f"Statement {i+1}: Dynamic SQL detected")
              return issues, warnings

          syntax_ok = validate_sql_syntax(script_path)
          issues, warnings = check_security_policies(script_path)
          affected = extract_affected_objects(script_path)

          report_dir = os.path.join(pipeline_workspace, 'sql')
          os.makedirs(report_dir, exist_ok=True)
          report_path = os.path.join(report_dir, 'validation_report.txt')
          with open(report_path, 'w', encoding='utf-8') as r:
              r.write("Validation report\n\n")
              r.write("Affected objects:\n")
              r.write(json.dumps(affected, indent=2))
              r.write("\n\nIssues:\n")
              r.write("\n".join(issues))
              r.write("\n\nWarnings:\n")
              r.write("\n".join(warnings))

          # Save affected objects for backup stage
          affected_json = os.path.join(report_dir, 'affected_objects.json')
          with open(affected_json, 'w', encoding='utf-8') as f:
              json.dump(affected, f, indent=2)

          if issues:
              print("##vso[task.logissue type=error]Security issues found:", issues)
              print("##vso[task.setvariable variable=hasSecurityIssues;isOutput=true]true")
              print("##vso[task.setvariable variable=hasWarnings;isOutput=true]true")
          else:
              print("No critical security issues found")
              print("##vso[task.setvariable variable=hasSecurityIssues;isOutput=true]false")
              print("##vso[task.setvariable variable=hasWarnings;isOutput=true]{}".format("true" if warnings else "false"))

      env:
        PIPELINE_WORKSPACE: $(Pipeline.Workspace)
        SQL_SCRIPT_PATH: $(sqlScriptPath)
        SQL_SCRIPT_NAME_PARAM: ${{ parameters.sqlScriptName }}

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Validation Report'
      condition: always()
      inputs:
        targetPath: '$(Pipeline.Workspace)/sql'
        artifact: 'ValidationReport'
        publishLocation: 'pipeline'

# ============================================================
# Security Review (Manual Approval) Stage
# ============================================================
- stage: Security_Review
  displayName: 'Security Review Required'
  dependsOn: Download_And_Validate
  condition: |
    and(
      succeeded(),
      or(
        eq(dependencies.Download_And_Validate.outputs['ValidateScript.SQLValidation.hasSecurityIssues'], 'true'),
        eq(dependencies.Download_And_Validate.outputs['ValidateScript.SQLValidation.hasWarnings'], 'true')
      )
    )

  jobs:
  - job: WaitForApproval
    displayName: 'Manual Security Approval'
    pool: server
    timeoutInMinutes: 1440
    steps:
    - task: ManualValidation@1
      inputs:
        notifyUsers: 'shubh.bhanushali@g7cr.com'
        approvers: 'shubh.bhanushali@g7cr.com'
        instructions: 'Issues found with the SQL script. Please check the validation file and approve/reject.'
        onTimeout: 'reject'

# ============================================================
# Backup Affected Database Objects Stage
# ============================================================
- stage: Backup_Database_Objects
  displayName: 'Backup User Database Objects'
  dependsOn:
    - Download_And_Validate
    - Security_Review
  condition: |
    and(
      not(failed()),
      not(canceled()),
      eq('${{ parameters.enableBackup }}', 'true'),
      eq('${{ parameters.dryRun }}', 'false')
    )

  jobs:
  - job: CreateBackup
    displayName: 'Backup Affected Database Objects'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 30
    steps:
    - checkout: none

    - task: DownloadPipelineArtifact@2
      displayName: 'Download Validation Results'
      inputs:
        artifact: 'ValidationReport'
        path: '$(Pipeline.Workspace)/sql'

    - task: AzurePowerShell@5
      name: BackupObjects
      displayName: 'Backup Affected Database Objects'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          try {
              Write-Host "Retrieving connection string from Key Vault..."
              $connectionString = Get-AzKeyVaultSecret -VaultName "$(keyVaultName)" -Name "$(secretName)" -AsPlainText
              if ([string]::IsNullOrEmpty($connectionString)) {
                  throw "Failed to retrieve connection string from Key Vault"
              }

              $timestamp = Get-Date -Format "yyyyMMdd_HHmmss"
              New-Item -ItemType Directory -Force -Path "$(backupPath)" | Out-Null
              $backupFile = "$(backupPath)/backup_$timestamp.sql"

              $affectedFile = "$(Pipeline.Workspace)/sql/affected_objects.json"
              $scriptArtifact = Get-ChildItem -Path "$(Pipeline.Workspace)/sql" -Filter *.sql -Recurse -ErrorAction SilentlyContinue | Select-Object -First 1
              if ($scriptArtifact) {
                  $scriptPath = $scriptArtifact.FullName
              } else {
                  $scriptPath = "$(sqlScriptPath)"
              }

              Write-Host "Using script at: $scriptPath"
              if (-not (Test-Path $scriptPath)) {
                  Write-Warning "Script not found, skipping live backup creation"
              } else {
                  # Read original script and remove NBSP and GO tokens
                  $orig = Get-Content -Path $scriptPath -Raw -ErrorAction Stop
                  $orig = $orig.Replace([char]0x00A0, [char]0x0020)
                  $origNoGo = $orig -replace '(?mi)^\s*GO\s*$',''  # remove standalone GO lines

                  # Find ALTER/DROP PROCEDURE blocks using regex simple heuristic
                  $procMatches = [regex]::Matches($origNoGo, '(?si)(ALTER|CREATE)\s+PROCEDURE\s+([^\r\n\(]+)\s*(\([^\)]*\))?.*?(?=(?:\r?\nCREATE|\r?\nALTER|\z))')

                  if ($procMatches.Count -gt 0) {
                      foreach ($m in $procMatches) {
                          # m.Groups[2] contains object name (may include schema)
                          $procNameRaw = $m.Groups[2].Value.Trim()
                          # normalize name (remove brackets if any)
                          $procNameClean = $procNameRaw -replace '^\[|\]$',''
                          # create backup name
                          $backupName = ($procNameClean -replace '[\[\]\.]','_') + "_backup_$timestamp"
                          # Build CREATE script for backup
                          $defBlock = $m.Value.Trim()
                          # Replace ALTER with CREATE for backup safety
                          $defBlock = $defBlock -replace '(?i)^\s*ALTER\s+PROCEDURE', 'CREATE PROCEDURE'
                          # Ensure CREATE line references backup name with schema preserved if present
                          if ($procNameClean -match '\.') {
                              $schema, $short = $procNameClean.Split('.',2)
                              $createLine = "CREATE PROCEDURE [$schema].[$backupName]"
                          } else {
                              $createLine = "CREATE PROCEDURE dbo.[$backupName]"
                          }
                          # Replace object's first CREATE/ALTER line
                          $defLines = $defBlock -split "`r?`n"
                          for ($i=0; $i -lt $defLines.Count; $i++) {
                              if ($defLines[$i] -match '^\s*(ALTER|CREATE)\s+PROCEDURE') {
                                  # Replace that line with new create line while preserving parameter list if on same line
                                  $rest = $defLines[$i] -replace '^\s*(ALTER|CREATE)\s+PROCEDURE\s+([^\r\n]*)', ''
                                  if ($rest) {
                                      $defLines[$i] = $createLine + " " + $rest.Trim()
                                  } else {
                                      $defLines[$i] = $createLine
                                  }
                                  # drop previous lines so CREATE is first in the batch
                                  $defLines = $defLines[$i..($defLines.Count-1)]
                                  break
                              }
                          }
                          $finalCreate = ($defLines -join "`r`n").Trim()
                          # remove any GO tokens inside finalCreate
                          $finalCreate = $finalCreate -replace '(?i)\bGO\b',''

                          # Attempt to drop existing backup proc if exists (safe cleanup)
                          $dropSql = "IF OBJECT_ID(N'$createLine','P') IS NOT NULL DROP PROCEDURE $createLine;"
                          # NOTE: $createLine includes schema and square brackets, but we will drop specific backup name below using fully-qualified name
                          try {
                              $fullyQualifiedBackup = if ($procNameClean -match '\.') { ("[" + $procNameClean.Split('.')[0] + "].[" + $backupName + "]") } else { ("[dbo].[" + $backupName + "]") }
                              $dropBackup = "IF OBJECT_ID(N'$fullyQualifiedBackup','P') IS NOT NULL DROP PROCEDURE $fullyQualifiedBackup;"
                              Invoke-Sqlcmd -ConnectionString $connectionString -Query $dropBackup -ErrorAction SilentlyContinue
                          } catch {
                              # ignore drop errors
                          }

                          try {
                              Write-Host "Creating live backup object: $fullyQualifiedBackup"
                              Invoke-Sqlcmd -ConnectionString $connectionString -Query $finalCreate -QueryTimeout 300 -ErrorAction Stop
                              Write-Host "  ✓ Live backup created: $fullyQualifiedBackup"
                          } catch {
                              Write-Warning "  Failed to create live backup for $procNameClean: $($_.Exception.Message)"
                          }

                          # Append original definition to backup file artifact for record
                          Add-Content -Path $backupFile -Value ("-- Backup for " + $procNameClean + " created at " + (Get-Date).ToString("s"))
                          Add-Content -Path $backupFile -Value $m.Value
                          Add-Content -Path $backupFile -Value "`r`nGO`r`n"
                      }
                  } else {
                      Write-Host "No procedure definitions detected for live backup creation."
                      # Still save the original script as a backup artifact
                      $orig | Out-File -FilePath $backupFile -Encoding UTF8
                  }
              }

              Write-Host "Backup artifact saved to $backupFile"
              Write-Host "##vso[task.setvariable variable=backupCompleted;isOutput=true]true"
              Write-Host "##vso[task.setvariable variable=backupBlobName;isOutput=true]backup_$timestamp.sql"
          }
          catch {
              Write-Warning "Backup step encountered an error: $($_.Exception.Message)"
              # Do not fail pipeline on backup errors by default; fail the job if you prefer
              # exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Backup Files'
      condition: always()
      inputs:
        targetPath: '$(backupPath)'
        artifact: 'DatabaseBackup'
        publishLocation: 'pipeline'

# ============================================================
# Execute SQL Script Stage
# ============================================================
- stage: Execute_SQL_Script
  displayName: 'Execute SQL Script'
  dependsOn:
    - Download_And_Validate
    - Security_Review
    - Backup_Database_Objects
  condition: |
    and(
      not(failed()),
      not(canceled()),
      eq('${{ parameters.dryRun }}', 'false')
    )

  jobs:
  - job: ExecuteScript
    displayName: 'Run SQL Script'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 60
    steps:
    - checkout: none

    - task: DownloadPipelineArtifact@2
      displayName: 'Download SQL Script'
      inputs:
        artifact: 'SQLScript'
        path: '$(Pipeline.Workspace)/sql'

    - task: AzurePowerShell@5
      name: ExecuteSQL
      displayName: 'Execute SQL Script'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          try {
              Write-Host "Retrieving connection string."
              $connectionString = Get-AzKeyVaultSecret -VaultName "$(keyVaultName)" -Name "$(secretName)" -AsPlainText
              if (-not $connectionString) {
                  throw "Connection string retrieval failed"
              }

              $scriptFile = Get-ChildItem -Path "$(Pipeline.Workspace)/sql" -Filter *.sql -Recurse | Select-Object -First 1
              if ($scriptFile) {
                  $scriptPath = $scriptFile.FullName
              } else {
                  $scriptPath = "$(sqlScriptPath)"
              }

              Write-Host "Executing SQL script at: $scriptPath"
              $scriptContent = Get-Content -Path $scriptPath -Raw -ErrorAction Stop
              # Normalize non-breaking spaces
              $scriptContent = $scriptContent.Replace([char]0x00A0, [char]0x0020)

              # Split into batches on lines that contain only GO (case-insensitive)
              $batches = @($scriptContent -split '(?mi)^\s*GO\s*$' | Where-Object { $_.Trim() -ne "" })
              Write-Host "Found $($batches.Count) batch(es) to execute."

              $batchIndex = 0
              foreach ($batch in $batches) {
                  $batchIndex++
                  $toExecute = $batch -replace '(?i)\bGO\b',''
                  $toExecute = $toExecute.Trim()
                  if ($toExecute -eq "") { continue }
                  Write-Host "Executing batch $batchIndex..."
                  try {
                      Invoke-Sqlcmd -ConnectionString $connectionString -Query $toExecute -QueryTimeout 600 -ErrorAction Stop
                      Write-Host "  ✓ Batch $batchIndex executed"
                  } catch {
                      Write-Host "Batch $batchIndex failed: $($_.Exception.Message)"
                      throw "SQL execution failed at batch $batchIndex"
                  }
              }

              Write-Host ""
              Write-Host "SQL SCRIPT EXECUTED SUCCESSFULLY" -ForegroundColor Green
              Write-Host "##vso[task.setvariable variable=executionResult;isOutput=true]Success"
          }
          catch {
              Write-Host ""
              Write-Host "SQL SCRIPT EXECUTION FAILED" -ForegroundColor Red
              Write-Host "Error: $($_.Exception.Message)" -ForegroundColor Red
              Write-Host "##vso[task.setvariable variable=executionResult;isOutput=true]Failed"
              Write-Host "##vso[task.logissue type=error]SQL execution failed: $($_.Exception.Message)"
              exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Execution Logs'
      condition: always()
      inputs:
        targetPath: '$(logsPath)'
        artifact: 'ExecutionLogs'
        publishLocation: 'pipeline'

# End of pipeline - Notification & Audit stage intentionally removed
