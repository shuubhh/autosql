name: $(Date:yyyyMMdd)$(Rev:.r)

trigger: none # Manual trigger only

parameters:
- name: sqlScriptName
  displayName: 'SQL Script Name'
  type: string
  default: 'script.sql'
- name: dryRun
  displayName: 'Dry Run (Validation Only)'
  type: boolean
  default: false
- name: enableBackup
  displayName: 'Enable Backup Before Execution'
  type: boolean
  default: true
- name: agentPool
  displayName: 'Agent Pool'
  type: string
  default: 'self1'

variables:
  sqlScriptPath: '$(Pipeline.Workspace)/sql/${{ parameters.sqlScriptName }}'
  backupPath: '$(Pipeline.Workspace)/backup'
  logsPath: '$(Pipeline.Workspace)/logs'
  storageAccountName: 'sqlautostacc'
  containerName: 'rawsql'
  backupContainerName: 'backups'
  keyVaultName: 'sql-validator-kv'
  secretName: 'sql-conn-string'

stages:
- stage: Download_And_Validate
  displayName: 'Download and Validate SQL Script'
  jobs:
  - job: DownloadScript
    displayName: 'Download SQL Script from Blob Storage'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 10
    
    steps:
    - checkout: none
    
    - task: PowerShell@2
      displayName: 'Verify Agent Prerequisites'
      inputs:
        targetType: 'inline'
        script: |
          Write-Host "Checking agent prerequisites..."
          
          # Check PowerShell version
          $psVersion = $PSVersionTable.PSVersion
          Write-Host "PowerShell Version: $psVersion"
          if ($psVersion.Major -lt 5) {
              Write-Error "PowerShell 5.0 or higher required"
              exit 1
          }
          
          # Check Python
          try {
              $pythonVersion = python --version 2>&1
              Write-Host "Python: $pythonVersion"
              
              # Check if sqlparse is installed
              $sqlparseCheck = python -c "import sqlparse; print('sqlparse is available')" 2>&1
              if ($LASTEXITCODE -ne 0) {
                  Write-Host "Installing sqlparse module..."
                  python -m pip install sqlparse==0.4.4
              } else {
                  Write-Host "✓ sqlparse module is already installed"
              }
          } catch {
              Write-Error "Python not found or not working properly. Please ensure Python 3.x is installed and in PATH"
              Write-Host "Available Python versions:"
              Get-Command python* -CommandType Application | Format-Table Name, Path
              exit 1
          }
          
          # Check Az PowerShell module
          $azModule = Get-Module -ListAvailable -Name Az.Accounts, Az.KeyVault, Az.Storage
          if (-not $azModule) {
              Write-Host "Installing Az PowerShell modules..."
              Install-Module -Name Az.Accounts, Az.KeyVault, Az.Storage -Force -AllowClobber -Scope CurrentUser
          }
          
          # Check SqlServer module
          $sqlModule = Get-Module -ListAvailable -Name SqlServer
          if (-not $sqlModule) {
              Write-Host "Installing SqlServer PowerShell module..."
              Install-Module -Name SqlServer -Force -AllowClobber -Scope CurrentUser
          }
          
          Write-Host "✓ Prerequisites verified"

    - task: AzurePowerShell@5
      displayName: 'Download SQL Script from Blob'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          
          try {
              Write-Host "Creating directory structure..."
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/sql" | Out-Null
              
              Write-Host "Downloading script: ${{ parameters.sqlScriptName }}"
              
              # Get storage account context
              $storageAccount = Get-AzStorageAccount | Where-Object { $_.StorageAccountName -eq "$(storageAccountName)" }
              
              if (-not $storageAccount) {
                  throw "Storage account '$(storageAccountName)' not found"
              }
              
              $ctx = $storageAccount.Context
              
              # Download blob
              Get-AzStorageBlobContent `
                  -Container "$(containerName)" `
                  -Blob "${{ parameters.sqlScriptName }}" `
                  -Destination "$(sqlScriptPath)" `
                  -Context $ctx `
                  -Force
              
              if (-not (Test-Path "$(sqlScriptPath)")) {
                  throw "Failed to download SQL script"
              }
              
              $fileSize = (Get-Item "$(sqlScriptPath)").Length
              Write-Host "✓ Script downloaded successfully ($fileSize bytes)"
              Write-Host "Script location: $(sqlScriptPath)"
              Get-Content "$(sqlScriptPath)" -TotalCount 5 | ForEach-Object { Write-Host "  $_" }
          }
          catch {
              Write-Error "Download failed: $($_.Exception.Message)"
              exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish SQL Script'
      inputs:
        targetPath: '$(Pipeline.Workspace)/sql'
        artifact: 'SQLScript'
        publishLocation: 'pipeline'

  - job: ValidateScript
    displayName: 'Syntax and Security Validation'
    dependsOn: DownloadScript
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 15
    
    steps:
    - checkout: none
    
    - task: DownloadPipelineArtifact@2
      displayName: 'Download SQL Script Artifact'
      inputs:
        artifact: 'SQLScript'
        path: '$(Pipeline.Workspace)/sql'

    - task: PythonScript@0
      name: SQLValidation
      displayName: 'SQL Syntax and Security Validation'
      inputs:
        scriptSource: 'inline'
        script: |
          import sqlparse
          import sys
          import os
          import re
          import json

          # Debug: Print environment variables and check paths
          print("=== DEBUG INFORMATION ===")
          print("Environment Variables:")
          for key, value in sorted(os.environ.items()):
              if any(term in key for term in ['WORK', 'AGENT', 'PIPELINE', 'BUILD', 'SCRIPT', 'SYSTEM']):
                  print(f"  {key}: {value}")

          # Get paths from environment variables
          pipeline_workspace = os.environ.get('PIPELINE_WORKSPACE')
          sql_script_path = os.environ.get('SQL_SCRIPT_PATH')

          print(f"\nPipeline Workspace from env: {pipeline_workspace}")
          print(f"SQL Script Path from env: {sql_script_path}")

          # If environment variables are not set, try alternative approaches
          if not pipeline_workspace:
              print("PIPELINE_WORKSPACE not found in environment, trying alternatives...")
              possible_workspaces = [
                  os.environ.get('AGENT_WORKFOLDER'),
                  os.environ.get('SYSTEM_DEFAULTWORKINGDIRECTORY'),
                  os.path.abspath('.')
              ]
              for workspace in possible_workspaces:
                  if workspace and os.path.exists(workspace):
                      pipeline_workspace = workspace
                      print(f"Using alternative workspace: {pipeline_workspace}")
                      break

          if not sql_script_path:
              print("SQL_SCRIPT_PATH not found in environment, constructing path...")
              if pipeline_workspace:
                  sql_script_path = os.path.join(pipeline_workspace, 'sql', os.path.basename(os.environ.get('SQL_SCRIPT_NAME_PARAM', 'script.sql')))
                  print(f"Constructed script path: {sql_script_path}")

          # Normalize paths
          if pipeline_workspace:
              report_dir = os.path.join(pipeline_workspace, 'sql')
          else:
              report_dir = 'sql'  # Fallback
              
          script_path = sql_script_path

          print(f"\nFinal Paths:")
          print(f"Report Directory: {report_dir}")
          print(f"Script Path: {script_path}")

          # Check if script file exists
          print(f"\nFile Check:")
          print(f"Script exists: {os.path.exists(script_path) if script_path else 'No path'}")
          if script_path and os.path.exists(script_path):
              print(f"Script size: {os.path.getsize(script_path)} bytes")
              # Show first few lines of the script
              try:
                  with open(script_path, 'r', encoding='utf-8') as f:
                      first_lines = []
                      for _ in range(5):
                          line = f.readline()
                          if not line:
                              break
                          first_lines.append(line.strip())
                  print(f"First lines: {first_lines}")
              except Exception as e:
                  print(f"Error reading script: {e}")
          else:
              # List files in possible locations
              print("Searching for SQL files...")
              search_dirs = [pipeline_workspace, 'sql', '.', os.path.join(pipeline_workspace, 'sql') if pipeline_workspace else 'sql']
              for search_dir in search_dirs:
                  if search_dir and os.path.exists(search_dir):
                      print(f"Files in {search_dir}:")
                      try:
                          for file in os.listdir(search_dir):
                              if file.endswith('.sql'):
                                  print(f"  - {file}")
                      except Exception as e:
                          print(f"  Error listing: {e}")

          print("=== END DEBUG ===\n")

          # Validate that we have a script path
          if not script_path or not os.path.exists(script_path):
              print("##vso[task.logissue type=error]SQL script not found")
              print(f"##vso[task.logissue type=error]Expected path: {script_path}")
              sys.exit(1)

          def validate_sql_syntax(file_path):
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      sql_content = f.read()
                  
                  if not sql_content.strip():
                      print("##vso[task.logissue type=error]SQL file is empty")
                      return False
                  
                  parsed = sqlparse.parse(sql_content)
                  if not parsed:
                      print("##vso[task.logissue type=error]Failed to parse SQL content")
                      return False
                  
                  print("Basic SQL syntax is valid")
                  print(f"  Found {len(parsed)} SQL statement(s)")
                  return True
              except Exception as e:
                  print(f"##vso[task.logissue type=error]SQL Syntax Error: {e}")
                  return False

          def extract_table_name_from_dml(statement):
              """
              Extract table name from UPDATE/DELETE statements - FIXED VERSION
              """
              # Clean the statement first to remove comments and strings
              clean_stmt = re.sub(r'--.*$', '', statement, flags=re.MULTILINE)
              clean_stmt = re.sub(r'/\*.*?\*/', '', clean_stmt, flags=re.DOTALL)
              clean_stmt = re.sub(r"'.*?'", "''", clean_stmt)
              clean_stmt = re.sub(r'".*?"', '""', clean_stmt)
              
              # Pattern for UPDATE table_name - more specific
              update_match = re.search(r'\bUPDATE\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)\b', clean_stmt, re.IGNORECASE)
              if update_match:
                  return update_match.group(1)
              
              # Pattern for DELETE FROM table_name or DELETE table_name - more specific
              delete_match = re.search(r'\bDELETE\s+(?:FROM\s+)?([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)\b', clean_stmt, re.IGNORECASE)
              if delete_match:
                  return delete_match.group(1)
              
              return None

          def extract_table_name_from_alter(statement):
              """
              Extract table name from ALTER TABLE statements - FIXED VERSION
              """
              # Clean the statement first to remove comments and strings
              clean_stmt = re.sub(r'--.*$', '', statement, flags=re.MULTILINE)
              clean_stmt = re.sub(r'/\*.*?\*/', '', clean_stmt, flags=re.DOTALL)
              clean_stmt = re.sub(r"'.*?'", "''", clean_stmt)
              clean_stmt = re.sub(r'".*?"', '""', clean_stmt)
              
              # Pattern for ALTER TABLE - more specific and avoids capturing 'ALTER' as table name
              alter_match = re.search(r'\bALTER\s+TABLE\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)\b', clean_stmt, re.IGNORECASE)
              if alter_match:
                  return alter_match.group(1)
              
              return None

          def check_security_policies(file_path):
              with open(file_path, 'r', encoding='utf-8') as f:
                  sql_content = f.read()
              
              issues = []
              warnings = []
              
              statements = sqlparse.parse(sql_content)
              
              for i, stmt in enumerate(statements):
                  stmt_str = str(stmt).strip()
                  if not stmt_str:
                      continue
                  
                  stmt_upper = stmt_str.upper()
                  stmt_num = i + 1
                  
                  # Check for UPDATE without WHERE clause in any SQL statement
                  if 'UPDATE' in stmt_upper:
                      # Remove comments and strings to avoid false positives
                      clean_stmt = re.sub(r'--.*$', '', stmt_upper, flags=re.MULTILINE)
                      clean_stmt = re.sub(r'/\*.*?\*/', '', clean_stmt, flags=re.DOTALL)
                      clean_stmt = re.sub(r"'.*?'", '', clean_stmt)
                      clean_stmt = re.sub(r'".*?"', '', clean_stmt)
                      
                      # Check if UPDATE has WHERE clause
                      if 'UPDATE' in clean_stmt and 'WHERE' not in clean_stmt:
                          table_name = extract_table_name_from_dml(stmt_str)
                          table_info = f" on table '{table_name}'" if table_name else ""
                          issues.append(f"Statement {stmt_num}: UPDATE without WHERE clause{table_info}")
                  
                  # Check for DELETE without WHERE clause in any SQL statement
                  if 'DELETE' in stmt_upper:
                      # Remove comments and strings to avoid false positives
                      clean_stmt = re.sub(r'--.*$', '', stmt_upper, flags=re.MULTILINE)
                      clean_stmt = re.sub(r'/\*.*?\*/', '', clean_stmt, flags=re.DOTALL)
                      clean_stmt = re.sub(r"'.*?'", '', clean_stmt)
                      clean_stmt = re.sub(r'".*?"', '', clean_stmt)
                      
                      # Check if DELETE has WHERE clause
                      if 'DELETE' in clean_stmt and 'WHERE' not in clean_stmt:
                          table_name = extract_table_name_from_dml(stmt_str)
                          table_info = f" on table '{table_name}'" if table_name else ""
                          issues.append(f"Statement {stmt_num}: DELETE without WHERE clause{table_info}")
                  
                  # Check for dangerous DROP operations with enhanced pattern matching
                  dangerous_drops = [
                      ('DROP TABLE', 'TABLE'),
                      ('DROP DATABASE', 'DATABASE'), 
                      ('DROP SCHEMA', 'SCHEMA'),
                      ('DROP PROCEDURE', 'PROCEDURE'),
                      ('DROP FUNCTION', 'FUNCTION'),
                      ('DROP VIEW', 'VIEW')
                  ]
                  
                  for drop_op, obj_type in dangerous_drops:
                      if drop_op in stmt_upper:
                          # Extract object name after DROP operation - FIXED regex
                          obj_match = re.search(rf'{re.escape(drop_op)}\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)\b', stmt_upper, re.IGNORECASE)
                          if obj_match:
                              obj_info = f" '{obj_match.group(1)}'"
                          else:
                              obj_info = ""
                          issues.append(f"Statement {stmt_num}: Dangerous operation - {drop_op}{obj_info}")
                  
                  # Check for TRUNCATE TABLE
                  if 'TRUNCATE TABLE' in stmt_upper or re.search(r'\bTRUNCATE\s+TABLE\b', stmt_upper):
                      # Extract table name after TRUNCATE TABLE - FIXED regex
                      table_match = re.search(r'TRUNCATE\s+TABLE\s+([a-zA-Z_][a-zA-Z0-9_]*(?:\.[a-zA-Z_][a-zA-Z0-9_]*)?)\b', stmt_upper, re.IGNORECASE)
                      if table_match:
                          table_info = f" '{table_match.group(1)}'"
                      else:
                          table_info = ""
                      issues.append(f"Statement {stmt_num}: TRUNCATE TABLE detected{table_info}")
                  
                  # Enhanced ALTER TABLE detection - FIXED
                  if 'ALTER TABLE' in stmt_upper:
                      table_name = extract_table_name_from_alter(stmt_str)
                      table_info = f" '{table_name}'" if table_name else ""
                      
                      # Check what type of ALTER operation
                      if re.search(r'\bADD\s+(?!CONSTRAINT)\w+', stmt_upper, re.IGNORECASE):
                          warnings.append(f"Statement {stmt_num}: ALTER TABLE ADD COLUMN operation{table_info}")
                      elif re.search(r'\bDROP\s+COLUMN\b', stmt_upper, re.IGNORECASE):
                          warnings.append(f"Statement {stmt_num}: ALTER TABLE DROP COLUMN operation{table_info}")
                      elif re.search(r'\bALTER\s+COLUMN\b', stmt_upper, re.IGNORECASE):
                          warnings.append(f"Statement {stmt_num}: ALTER TABLE MODIFY COLUMN operation{table_info}")
                      else:
                          warnings.append(f"Statement {stmt_num}: ALTER TABLE operation{table_info}")
                  
                  # Check for Dynamic SQL (warning only)
                  if re.search(r'\bEXEC\s*\(|\bEXECUTE\s*\(|\bSP_EXECUTESQL\b', stmt_upper):
                      warnings.append(f"Statement {stmt_num}: Dynamic SQL detected")
              
              return issues, warnings

          # *** NEW FUNCTION ***
          # This function identifies objects to be backed up (ALTER/DROP)
          def extract_affected_objects(file_path):
              with open(file_path, 'r', encoding='utf-8') as f:
                  sql_content = f.read()

              # Remove comments to avoid false positives
              sql_content = re.sub(r'--.*$', '', sql_content, flags=re.MULTILINE)
              sql_content = re.sub(r'/\*.*?\*/', '', sql_content, flags=re.DOTALL)
              
              objects_to_backup = []
              
              # Regex to find ALTER or DROP commands for procedures, functions, views, or tables
              # Group 1: ALTER or DROP
              # Group 2: PROCEDURE, FUNCTION, VIEW, TABLE
              # Group 3: Object name (e.g., [dbo].[myProc], dbo.myProc, [myProc], myProc)
              pattern = re.compile(
                  r'\b(ALTER|DROP)\s+(PROCEDURE|FUNCTION|VIEW|TABLE)\s+((?:\[[^\]]+\]|[\w\d_]+)\.(?:\[[^\]]+\]|[\w\d_]+)|(?:\[[^\]]+\]|[\w\d_]+))',
                  re.IGNORECASE | re.MULTILINE
              )
              
              # Keep track of unique objects to avoid duplicates
              unique_objects = set()

              for match in pattern.finditer(sql_content):
                  action = match.group(1).upper()
                  obj_type = match.group(2).upper()
                  full_name = match.group(3)
                  
                  # Parse schema and name
                  schema = 'dbo' # Default schema
                  name = full_name
                  
                  if '.' in full_name:
                      parts = full_name.split('.')
                      # Handle [schema].[object]
                      schema = parts[0].strip().strip('[]')
                      name = '.'.join(parts[1:]).strip().strip('[]') # Handle names with dots if any (unlikely but safe)
                  else:
                      name = full_name.strip().strip('[]')
                  
                  # Create a unique key for this object
                  obj_key = (schema.lower(), name.lower(), obj_type)
                  
                  if obj_key not in unique_objects:
                      objects_to_backup.append({
                          'schema': schema,
                          'name': name,
                          'type': obj_type,
                          'action': action
                      })
                      unique_objects.add(obj_key)
              
              # Separate scriptable objects (proc, func, view) from tables
              scriptable_objects = [obj for obj in objects_to_backup if obj['type'] in ('PROCEDURE', 'FUNCTION', 'VIEW')]
              table_objects = [obj for obj in objects_to_backup if obj['type'] == 'TABLE']

              # This is for the human-readable text report
              affected_report = {
                  'procedures': list(set([f"{obj['schema']}.{obj['name']}" for obj in scriptable_objects if obj['type'] == 'PROCEDURE'])),
                  'functions': list(set([f"{obj['schema']}.{obj['name']}" for obj in scriptable_objects if obj['type'] == 'FUNCTION'])),
                  'views': list(set([f"{obj['schema']}.{obj['name']}" for obj in scriptable_objects if obj['type'] == 'VIEW'])),
                  'tables': list(set([f"{obj['schema']}.{obj['name']}" for obj in table_objects]))
              }

              # This is the JSON data that will be used by the backup stage
              backup_data = {
                  'scriptableObjects': scriptable_objects,
                  'tableObjects': table_objects
              }
              
              return backup_data, affected_report

          # *** MODIFIED FUNCTION ***
          # Now saves the correct JSON for the backup stage
          def generate_report(file_path, syntax_ok, issues, warnings, affected_report_data, backup_json_data, report_dir):
              # Use the report_dir we defined earlier
              os.makedirs(report_dir, exist_ok=True)
              report_path = os.path.join(report_dir, 'validation_report.txt')
              
              # Use UTF-8 encoding to handle special characters
              with open(report_path, 'w', encoding='utf-8') as f:
                  f.write("=" * 70 + "\n")
                  f.write("SQL VALIDATION REPORT\n")
                  f.write("=" * 70 + "\n\n")
                  f.write(f"Script: {os.path.basename(file_path)}\n")
                  f.write(f"Syntax Valid: {'YES' if syntax_ok else 'NO'}\n\n")
                  
                  # Use the affected_report_data for the text report
                  affected = affected_report_data
                  if any(affected.values()):
                      f.write("AFFECTED DATABASE OBJECTS (from ALTER or DROP):\n")
                      f.write("-" * 70 + "\n")
                      if affected['procedures']:
                          f.write(f"  Procedures: {', '.join(set(affected['procedures']))}\n")
                      if affected['functions']:
                          f.write(f"  Functions: {', '.join(set(affected['functions']))}\n")
                      if affected['views']:
                          f.write(f"  Views: {', '.join(set(affected['views']))}\n")
                      if affected['tables']:
                          f.write(f"  Tables: {', '.join(set(affected['tables']))}\n")
                      f.write("\n")
                  else:
                      f.write("No objects identified for backup (ALTER/DROP statements not found)\n\n")
                  
                  if issues:
                      f.write(f"CRITICAL ISSUES ({len(issues)}):\n")
                      f.write("-" * 70 + "\n")
                      for issue in issues:
                          f.write(f"  [ISSUE] {issue}\n")
                      f.write("\n")
                  
                  if warnings:
                      f.write(f"WARNINGS ({len(warnings)}):\n")
                      f.write("-" * 70 + "\n")
                      for warning in warnings:
                          f.write(f"  [WARNING] {warning}\n")
                      f.write("\n")
                  
                  if not issues and not warnings:
                      f.write("No security issues detected\n\n")
                  
                  f.write("=" * 70 + "\n")
              
              # Save the backup_json_data to affected_objects.json for the next stage
              affected_path = os.path.join(report_dir, 'affected_objects.json')
              with open(affected_path, 'w', encoding='utf-8') as f:
                  # This is the new structure
                  json.dump(backup_json_data, f, indent=2)
              
              print(f"Validation report generated: {report_path}")
              print(f"Affected objects JSON saved: {affected_path}")

          # --- MAIN EXECUTION ---
          print(f"Validating SQL script: {script_path}\n")

          syntax_ok = validate_sql_syntax(script_path)
          issues, warnings = check_security_policies(script_path)
          
          # New function returns two values
          backup_data, affected_report = extract_affected_objects(script_path)

          # Pass all data to the report function
          generate_report(script_path, syntax_ok, issues, warnings, affected_report, backup_data, report_dir)

          if issues:
              print("\n" + "=" * 70)
              print(f"CRITICAL ISSUES FOUND ({len(issues)}):")
              print("=" * 70)
              for issue in issues:
                  print(f"  {issue}")
                  print(f"##vso[task.logissue type=error]{issue}")
              print('##vso[task.setvariable variable=hasSecurityIssues;isOutput=true]true')
              print('##vso[task.setvariable variable=hasWarnings;isOutput=true]true')
          else:
              print("\nNo critical security issues found")
              print('##vso[task.setvariable variable=hasSecurityIssues;isOutput=true]false')
          
          if warnings:
              print("\n" + "=" * 70)
              print(f"WARNINGS ({len(warnings)}):\n")
              print("=" * 70)
              for warning in warnings:
                  print(f"  {warning}")
                  print(f"##vso[task.logissue type=warning]{warning}")
              print('##vso[task.setvariable variable=hasWarnings;isOutput=true]true')
          else:
              print('##vso[task.setvariable variable=hasWarnings;isOutput=true]false')

          if not syntax_ok:
              print("\n##vso[task.complete result=Failed;]Syntax validation failed")
              sys.exit(1)

          print("\nValidation completed successfully")
      env:
        PIPELINE_WORKSPACE: $(Pipeline.Workspace)
        SQL_SCRIPT_PATH: $(sqlScriptPath)
        SQL_SCRIPT_NAME_PARAM: ${{ parameters.sqlScriptName }}

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Validation Report'
      condition: always()
      inputs:
        targetPath: '$(Pipeline.Workspace)/sql'
        artifact: 'ValidationReport'
        publishLocation: 'pipeline'

- stage: Security_Review
  displayName: 'Security Review Required'
  dependsOn: Download_And_Validate
  condition: |
    and(
      succeeded(),
      or(
        eq(dependencies.Download_And_Validate.outputs['ValidateScript.SQLValidation.hasSecurityIssues'], 'true'),
        eq(dependencies.Download_And_Validate.outputs['ValidateScript.SQLValidation.hasWarnings'], 'true')
      )
    )
  
  jobs:
  - job: WaitForApproval
    displayName: 'Manual Security Approval'
    pool: server
    timeoutInMinutes: 1440
    
    steps:
    
    - task: ManualValidation@1
      inputs:
        notifyUsers: 'shubh.bhanushali@g7cr.com'
        approvers: 'shubh.bhanushali@g7cr.com'
        instructions: 'Issues found with the sql script. please check the validation file and approve/reject'
        onTimeout: 'reject'

- stage: Backup_Database_Objects
  displayName: 'Backup User Database Objects'
  dependsOn: 
    - Download_And_Validate
    - Security_Review
  condition: |
    and(
      not(failed()),
      not(canceled()),
      eq('${{ parameters.enableBackup }}', 'true'),
      eq('${{ parameters.dryRun }}', 'false')
    )
  
  jobs:
  - job: CreateBackup
    displayName: 'Backup Affected Database Objects'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 30
    
    steps:
    - checkout: none
    
    - task: DownloadPipelineArtifact@2
      displayName: 'Download Validation Results'
      inputs:
        artifact: 'ValidationReport'
        path: '$(Pipeline.Workspace)/sql'

    - task: AzurePowerShell@5
      name: BackupObjects
      displayName: 'Backup Affected Database Objects'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          
          # Helper function to escape object names for regex replacement
          function Escape-SqlName {
              param([string]$name)
              # Escapes special characters in the name and handles brackets [ ]
              return [regex]::Escape($name).Replace('\\[', '[').Replace('\\]', ']').Replace('\\.', '.')
          }
          
          try {
              Write-Host "Retrieving connection string from Key Vault..."
              $connectionString = Get-AzKeyVaultSecret -VaultName "$(keyVaultName)" -Name "$(secretName)" -AsPlainText
              
              if ([string]::IsNullOrEmpty($connectionString)) {
                  throw "Failed to retrieve connection string from Key Vault"
              }
              
              Write-Host "Reading affected objects list..."
              $affectedObjectsPath = "$(Pipeline.Workspace)/sql/affected_objects.json"
              $timestamp = Get-Date -Format "yyyyMMdd_HHmmss"
              $backupFile = "$(backupPath)/backup_$timestamp.sql"
              
              if (-not (Test-Path $affectedObjectsPath)) {
                  Write-Host "No 'affected_objects.json' file found. No objects to back up."
                  Write-Host "##vso[task.setvariable variable=backupCompleted;isOutput=true]true"
                  Write-Host "##vso[task.setvariable variable=backupBlobName;isOutput=true]none"
                  Write-Host "##vso[task.setvariable variable=objectsBackedUp;isOutput=true]0"
                  exit 0
              }
              
              $affectedData = Get-Content $affectedObjectsPath | ConvertFrom-Json
              $scriptableObjects = $affectedData.scriptableObjects
              $tableObjects = $affectedData.tableObjects
              
              if ($scriptableObjects.Count -eq 0 -and $tableObjects.Count -eq 0) {
                  Write-Host "No objects marked for ALTER or DROP. No backup needed."
                  Write-Host "##vso[task.setvariable variable=backupCompleted;isOutput=true]true"
                  Write-Host "##vso[task.setvariable variable=backupBlobName;isOutput=true]none"
                  Write-Host "##vso[task.setvariable variable=objectsBackedUp;isOutput=true]0"
                  exit 0
              }
              
              New-Item -ItemType Directory -Force -Path '$(backupPath)' | Out-Null
              
              $backupScriptContent = @"
          -- ============================================================
          -- DATABASE BACKUP SCRIPT (AFFECTED OBJECTS ONLY)
          -- ============================================================
          -- Generated: $(Get-Date -Format "yyyy-MM-dd HH:mm:ss")
          -- Build: $(Build.BuildNumber)
          -- Original Script: ${{ parameters.sqlScriptName }}
          -- Backs up definitions for objects targeted by ALTER/DROP
          -- ============================================================
          
          "@
              
              $objectsBackedUp = 0
              $tablesCopied = 0
              
              # --------------------------------------------------------------------------
              # 1. Backup definitions AND create backup objects for Procs, Funcs, Views
              # --------------------------------------------------------------------------
              if ($scriptableObjects.Count -gt 0) {
                  Write-Host "Backing up definitions and creating live backup objects for $($scriptableObjects.Count) scriptable object(s)..."
                  $backupScriptContent += "`r`n-- ========================================`r`n"
                  $backupScriptContent += "-- SCRIPTED OBJECT DEFINITIONS & LIVE BACKUPS (PROCEDURE, FUNCTION, VIEW)`r`n"
                  $backupScriptContent += "-- ========================================`r`n`r`n"
          
                  foreach ($obj in $scriptableObjects) {
                      $originalFullName = "[$($obj.schema)].[$($obj.name)]"
                      $backupObjectName = "$($obj.name)_backup_$timestamp"
                      $backupFullName = "[$($obj.schema)].[$backupObjectName]"
                      $objectType = $obj.type
                      
                      Write-Host "  Processing $objectType: $originalFullName"
                      
                      # Use OBJECT_ID with schema and name
                      $objectIdQuery = "SELECT OBJECT_ID('$($obj.schema).$($obj.name)')"
                      $objId = Invoke-Sqlcmd -ConnectionString $connectionString -Query $objectIdQuery -ErrorAction SilentlyContinue
                      
                      if ($objId -and $objId.Item(0) -ne $null) {
                          $query = "SELECT OBJECT_DEFINITION($($objId.Item(0))) AS Definition"
                          try {
                              $result = Invoke-Sqlcmd -ConnectionString $connectionString -Query $query -MaxCharLength 65535 -ErrorAction Stop
                              
                              if ($result -and $result.Definition) {
                                  $definition = $result.Definition
                                  
                                  # Add definition to the artifact script (as before)
                                  $backupScriptContent += "-- Object Definition: $originalFullName ($objectType)`r`n"
                                  $backupScriptContent += $definition + "`r`n"
                                  $backupScriptContent += "GO`r`n`r`n"
                                  
                                  # --------------------------------------------------------
                                  # NEW LOGIC: Create the live backup object in the database
                                  # --------------------------------------------------------
                                  Write-Host "    Attempting to create live backup object: $backupFullName"

                                  # 1. Clean up potential existing backup (safety check)
                                  $dropBackupSql = "IF OBJECT_ID('$backupFullName', 'P') IS NOT NULL DROP PROCEDURE $backupFullName; `r`n" +
                                                   "IF OBJECT_ID('$backupFullName', 'FN') IS NOT NULL DROP FUNCTION $backupFullName; `r`n" +
                                                   "IF OBJECT_ID('$backupFullName', 'V') IS NOT NULL DROP VIEW $backupFullName; `r`n"
                                  Invoke-Sqlcmd -ConnectionString $connectionString -Query $dropBackupSql -ErrorAction SilentlyContinue

                                  # 2. Modify the Definition Script to use the backup name
                                  # We need to find the definition line (e.g., CREATE PROCEDURE [dbo].[my_proc]) and replace [dbo].[my_proc]
                                  
                                  # Find the object type declaration line (e.g., CREATE PROCEDURE or ALTER PROCEDURE)
                                  $pattern = "^(\s*(?:CREATE|ALTER)\s+$objectType\s+)(?:\[.*?\].\[.*?\]|.*?\..*?)\s*"
                                  
                                  # Safely replace the object name on the definition line using regex and PowerShell's -replace operator
                                  # Note: The object name is usually right after "CREATE/ALTER PROCEDURE/FUNCTION/VIEW"
                                  
                                  # Use the name without brackets for the search pattern, then the bracketed version for replacement
                                  $nameToFind = "$($obj.schema).$($obj.name)"
                                  
                                  # Create the replacement full name (without brackets, for replacement target)
                                  $replacementName = "$($obj.schema).$backupObjectName"

                                  # Split definition into lines to find the object declaration line
                                  $lines = $definition -split "`r`n"
                                  $modifiedDefinition = $definition

                                  # Find the first line that contains "CREATE" or "ALTER" + object type
                                  for ($i = 0; $i -lt $lines.Count; $i++) {
                                      $line = $lines[$i].Trim()
                                      if ($line -match "^(CREATE|ALTER)\s+$objectType\s+") {
                                          # Use a precise replacement: search for the original name or its bracketed forms
                                          $nameRegex = [regex]::Escape($nameToFind).Replace('\[', '\[?').Replace('\]', '\]?')
                                          
                                          # Try to replace the original object name with the backup object name
                                          $newLine = $lines[$i] -replace "(?mi)(CREATE|ALTER)\s+$objectType\s+.*", "`$1 $objectType $replacementName"
                                          
                                          # If the line replacement worked (not null/empty), update the definition
                                          if ($newLine -ne $lines[$i]) {
                                              $lines[$i] = $newLine
                                              $modifiedDefinition = $lines -join "`r`n"
                                              break # Found and replaced the line
                                          }
                                      }
                                  }
                                  
                                  $liveBackupQuery = $modifiedDefinition
                                  # Ensure it uses CREATE not ALTER if we modified the line
                                  $liveBackupQuery = $liveBackupQuery -replace "(?mi)^\s*ALTER\s+$objectType", "CREATE $objectType"
                                  
                                  
                                  # Execute the new CREATE command
                                  Invoke-Sqlcmd -ConnectionString $connectionString -Query $liveBackupQuery -QueryTimeout 300 -ErrorAction Stop
                                  Write-Host "    ✓ Live backup object created: $backupFullName"
                                  $objectsBackedUp++
                              } else {
                                  Write-Warning "  Could not script definition for $originalFullName."
                              }
                          }
                          catch {
                              $errorMessage = $_.Exception.Message
                              Write-Warning "  Failed to script or create live backup for ${originalFullName}: ${errorMessage}"
                          }
                      } else {
                          Write-Warning "  Could not find object $originalFullName. Skipping definition and live backup."
                      }
                  }
              }
              
              # ----------------------------------------------------
              # 2. Backup Tables by copying them (SELECT * INTO)
              #    (This section remains the same, as it already creates a live backup object)
              # ----------------------------------------------------
              if ($tableObjects.Count -gt 0) {
                  Write-Host "Backing up $($tableObjects.Count) table(s) by copying..."
                  $backupScriptContent += "`r`n-- ========================================`r`n"
                  $backupScriptContent += "-- TABLE BACKUPS (COPIES)`r`n"
                  $backupScriptContent += "-- ========================================`r`n`r`n"
          
                  foreach ($table in $tableObjects) {
                      $fullName = "[$($table.schema)].[$($table.name)]"
                      $backupTableName = "[$($table.schema)].[$($table.name)_backup_$timestamp]"
                      Write-Host "  Copying table $fullName to $backupTableName"
                      
                      # Note: Schema and name are already parsed, removing extra brackets from $fullName
                      $copyQuery = @"
          -- Backup for table $($table.schema).$($table.name)
          IF OBJECT_ID('$($table.schema).$($table.name)', 'U') IS NOT NULL AND OBJECT_ID('$($table.schema).$($table.name)_backup_$timestamp', 'U') IS NULL
          BEGIN
              BEGIN TRY
                  SELECT * INTO $backupTableName FROM [$($table.schema)].[$($table.name)];
                  PRINT 'Successfully copied [$($table.schema)].[$($table.name)] to $backupTableName';
              END TRY
              BEGIN CATCH
                  PRINT 'ERROR: Failed to copy [$($table.schema)].[$($table.name)]. Error: ' + ERROR_MESSAGE();
              END CATCH
          END
          ELSE IF OBJECT_ID('$($table.schema).$($table.name)', 'U') IS NULL
          BEGIN
              PRINT 'WARNING: Table [$($table.schema)].[$($table.name)] does not exist. Cannot create backup copy.';
          END
          ELSE
          BEGIN
              PRINT 'WARNING: Backup table $backupTableName already exists. Skipping copy.';
          END
          GO
          "@
                      
                      $backupScriptContent += $copyQuery
                      
                      try {
                          # Execute the copy operation right now
                          Invoke-Sqlcmd -ConnectionString $connectionString -Query $copyQuery -QueryTimeout 300 -ErrorAction Stop
                          Write-Host "    Successfully executed copy command for $fullName"
                          $tablesCopied++
                      }
                      catch {
                          $errorMessage = $_.Exception.Message
                          Write-Warning "  Failed to execute copy for ${fullName}: ${errorMessage}"
                      }
                  }
              }
          
              $totalBackedUp = $objectsBackedUp + $tablesCopied
              
              if ($totalBackedUp -eq 0) {
                  Write-Host "No existing objects were found to back up."
                  $backupScriptContent += "`r`n-- No existing objects were found to back up`r`n"
              }
              
              $backupScriptContent | Out-File -FilePath $backupFile -Encoding UTF8
              Write-Host "Backup script saved to: $backupFile"
              Write-Host "Total objects scripted and copied (live): $objectsBackedUp"
              Write-Host "Total tables copied (live): $tablesCopied"
              
              Write-Host "Uploading backup script and log to Azure Storage..."
              $blobName = "backup_$(Build.BuildNumber)_$timestamp.sql"
              
              $storageAccount = Get-AzStorageAccount | Where-Object { $_.StorageAccountName -eq "$(storageAccountName)" }
              $ctx = $storageAccount.Context
              
              Set-AzStorageBlobContent `
                  -File $backupFile `
                  -Container "$(backupContainerName)" `
                  -Blob $blobName `
                  -Context $ctx `
                  -Force
              
              Write-Host "Backup completed successfully"
              Write-Host "  Backup location: $(backupContainerName)/$blobName"
              
              Write-Host "##vso[task.setvariable variable=backupCompleted;isOutput=true]true"
              Write-Host "##vso[task.setvariable variable=backupBlobName;isOutput=true]$blobName"
              Write-Host "##vso[task.setvariable variable=objectsBackedUp;isOutput=true]$totalBackedUp"
          }
          catch {
              Write-Error "Backup failed: $($_.Exception.Message)"
              exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Backup Files'
      condition: always()
      inputs:
        targetPath: '$(backupPath)'
        artifact: 'DatabaseBackup'
        publishLocation: 'pipeline'

- stage: Execute_SQL_Script
  displayName: 'Execute SQL Script'
  dependsOn: 
    - Download_And_Validate
    - Security_Review
    - Backup_Database_Objects
  condition: |
    and(
      not(failed()),
      not(canceled()),
      eq('${{ parameters.dryRun }}', 'false')
    )
  
  jobs:
  - job: ExecuteScript
    displayName: 'Run SQL Script'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 60
    
    steps:
    - checkout: none
    
    - task: DownloadPipelineArtifact@2
      displayName: 'Download SQL Script'
      inputs:
        artifact: 'SQLScript'
        path: '$(Pipeline.Workspace)/sql'

    - task: AzurePowerShell@5
      name: ExecuteSQL
      displayName: 'Execute SQL Script'
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Stop"
          
          try {
              Write-Host "Retrieving connection string..."
              $connectionString = Get-AzKeyVaultSecret -VaultName "$(keyVaultName)" -Name "$(secretName)" -AsPlainText
              
              Write-Host "Reading SQL script..."
              $scriptContent = Get-Content -Path '$(sqlScriptPath)' -Raw
              
              if ([string]::IsNullOrEmpty($scriptContent)) {
                  throw "SQL script is empty"
              }
              
              New-Item -ItemType Directory -Force -Path "$(logsPath)" | Out-Null
              $logFile = "$(logsPath)/execution_log.txt"
              
              $logHeader = @"
          ========================================
          SQL SCRIPT EXECUTION LOG
          ========================================
          Build: $(Build.BuildNumber)
          Script: ${{ parameters.sqlScriptName }}
          Started: $(Get-Date -Format "yyyy-MM-dd HH:mm:ss")
          ========================================
          
          "@
              $logHeader | Out-File -FilePath $logFile -Encoding UTF8
              
              # Split into batches on lines that contain only GO (case-insensitive), coerce to array, and remove empty entries
              $statements = @($scriptContent -split '(?mi)^\s*GO\s*$') | Where-Object { $_.Trim() -ne "" }
              
              Write-Host "Found $($statements.Count) statement batch(es)"
              
              $executedCount = 0
              $totalDuration = [TimeSpan]::Zero
              
              # Use foreach over statements to avoid indexing/singular string issues
              foreach ($statement in $statements) {
                  $statement = $statement.Trim()
                  
                  if ([string]::IsNullOrWhiteSpace($statement)) {
                      continue
                  }
                  
                  $executedCountForPreview = $executedCount + 1
                  $preview = if ($statement.Length -gt 150) { $statement.Substring(0, 150) + "..." } else { $statement }
                  
                  Write-Host ""
                  Write-Host "Executing batch $executedCountForPreview of $($statements.Count)"
                  Write-Host $preview
                  
                  "Batch $executedCountForPreview - $(Get-Date -Format 'HH:mm:ss')" | Out-File -FilePath $logFile -Append
                  $preview | Out-File -FilePath $logFile -Append
                  
                  try {
                      $startTime = Get-Date
                      
                      Invoke-Sqlcmd -ConnectionString $connectionString `
                                    -Query $statement `
                                    -QueryTimeout 600 `
                                    -ErrorAction Stop
                      
                      $duration = (Get-Date) - $startTime
                      $totalDuration += $duration
                      $executedCount++
                      
                      $successMsg = "Batch $executedCountForPreview completed in $([math]::Round($duration.TotalSeconds, 2))s"
                      Write-Host $successMsg -ForegroundColor Green
                      "$successMsg`n" | Out-File -FilePath $logFile -Append
                  }
                  catch {
                      $errorMsg = "Batch $executedCountForPreview failed: $($_.Exception.Message)"
                      Write-Host $errorMsg -ForegroundColor Red
                      "$errorMsg`n" | Out-File -FilePath $logFile -Append
                      throw "SQL execution failed at batch $executedCountForPreview"
                  }
              }
              
              Write-Host ""
              Write-Host "SQL SCRIPT EXECUTED SUCCESSFULLY" -ForegroundColor Green
              Write-Host "Batches executed: $executedCount" -ForegroundColor Green
              Write-Host "Total duration: $([math]::Round($totalDuration.TotalSeconds, 2))s" -ForegroundColor Green
              
              Write-Host "##vso[task.setvariable variable=executionResult;isOutput=true]Success"
              Write-Host "##vso[task.setvariable variable=executedCount;isOutput=true]$executedCount"
              Write-Host "##vso[task.setvariable variable=totalDuration;isOutput=true]$([math]::Round($totalDuration.TotalSeconds, 2))"
          }
          catch {
              Write-Host ""
              Write-Host "SQL SCRIPT EXECUTION FAILED" -ForegroundColor Red
              Write-Host "Error: $($_.Exception.Message)" -ForegroundColor Red
              
              Write-Host "##vso[task.setvariable variable=executionResult;isOutput=true]Failed"
              Write-Host "##vso[task.logissue type=error]SQL execution failed"
              
              exit 1
          }

    - task: PublishPipelineArtifact@1
      displayName: 'Publish Execution Logs'
      condition: always()
      inputs:
        targetPath: '$(logsPath)'
        artifact: 'ExecutionLogs'
        publishLocation: 'pipeline'

- stage: Notify_And_Audit
  displayName: 'Notification and Audit'
  dependsOn: 
    - Download_And_Validate
    - Backup_Database_Objects
    - Execute_SQL_Script
  condition: always()
  
  jobs:
  - job: SendNotification
    displayName: 'Send Execution Results'
    pool:
      name: ${{ parameters.agentPool }}
    timeoutInMinutes: 10
    
    steps:
    - checkout: none
    
    - task: PowerShell@2
      displayName: 'Generate Execution Summary'
      inputs:
        targetType: 'inline'
        script: |
          $result = "$(ExecuteSQL.executionResult)"
          $buildNumber = "$(Build.BuildNumber)"
          $scriptName = "${{ parameters.sqlScriptName }}"
          $isDryRun = "${{ parameters.dryRun }}"
          
          Write-Host ""
          Write-Host "=" * 70
          Write-Host "PIPELINE EXECUTION SUMMARY"
          Write-Host "=" * 70
          Write-Host "Build Number: $buildNumber"
          Write-Host "Script Name: $scriptName"
          Write-Host "Dry Run Mode: $isDryRun"
          Write-Host "Executed By: $(Build.RequestedFor)"
          
          if ($isDryRun -eq "true") {
              Write-Host ""
              Write-Host "DRY RUN COMPLETED - VALIDATION ONLY" -ForegroundColor Cyan
          }
          elseif ($result -eq "Success") {
              Write-Host ""
              Write-Host "EXECUTION SUCCESSFUL" -ForegroundColor Green
          } else {
              Write-Host ""
              Write-Host "EXECUTION FAILED" -ForegroundColor Red
          }
          
          Write-Host "=" * 70

    - task: AzurePowerShell@5
      displayName: 'Create Audit Trail'
      condition: eq('${{ parameters.dryRun }}', 'false')
      inputs:
        azureSubscription: 'Azure-Connection'
        ScriptType: 'InlineScript'
        azurePowerShellVersion: 'LatestVersion'
        Inline: |
          $ErrorActionPreference = "Continue"
          
          try {
              $auditLog = @{
                  buildNumber = "$(Build.BuildNumber)"
                  buildId = "$(Build.BuildId)"
                  scriptName = "${{ parameters.sqlScriptName }}"
                  executionResult = "$(ExecuteSQL.executionResult)"
                  executedBy = "$(Build.RequestedFor)"
                  executedAt = (Get-Date).ToUniversalTime().ToString("yyyy-MM-ddTHH:mm:ssZ")
                  dryRun = "${{ parameters.dryRun }}"
              } | ConvertTo-Json
              
              $auditFile = "audit_$(Build.BuildNumber)_$(Get-Date -Format 'yyyyMMdd_HHmmss').json"
              $auditLog | Out-File -FilePath $auditFile -Encoding UTF8
              
              Write-Host "Audit log created: $auditFile"
              
              $storageAccount = Get-AzStorageAccount | Where-Object { $_.StorageAccountName -eq "$(storageAccountName)" }
              
              if ($storageAccount) {
                  $ctx = $storageAccount.Context
                  
                  $container = Get-AzStorageContainer -Name "audit-logs" -Context $ctx -ErrorAction SilentlyContinue
                  if (-not $container) {
                      New-AzStorageContainer -Name "audit-logs" -Context $ctx -Permission Off
                  }
                  
                  Set-AzStorageBlobContent `
                      -File $auditFile `
                      -Container "audit-logs" `
                      -Blob $auditFile `
                      -Context $ctx `
                      -Force
                  
                  Write-Host "Audit log uploaded to blob storage"
              }
          }
          catch {
              Write-Warning "Failed to create audit trail: $($_.Exception.Message)"
          }
